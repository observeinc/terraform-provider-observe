extend type Query {
    """
    Provide a question to answer (up to 255 characters) and any previous
    question IDs.
    """
    getHelp(question: String!, previousIds: [String!]): HelpResponse!
    """
    If you have an ID token from a previous question, you can retrieve the entire history of that conversation, assuming it's yours and not some other users.
    """
    getHelpHistory(qid: String!): [HelpRecord!]!
    """
    Given some context, generate code completions.
    The outputStage of the query is the stage we want to complete for, and
    the contextLine is where we want text. If omitted or outside the text,
    we assume the cursor is at the end of the text of that stage.
    If the cursor is at the very start of the text, it is on line 1. This means
    that line 0 means "end of text" as per the above.
    You can request between 1 and 7 completions. Larger number of completions
    for big code snippets may not work. The default is 3.
    You can also provide ids for previous completions for as-yet TBD context.
    If you increase randomness (default 0) you will get different responses.
    This is helpful if all responses you got were bad and the user wants to
    see something else. Useful values are 0 .. 10
    """
    getCodeCompletion(query: MultiStageQueryInput!, contextLine: Int64, numCompletions: Int64, previousIds: [String!], randomness: Int64, model: CodeCompletionModel, objectKind: ObjectKind): CodeCompletionResponse!
    """
    Given some data, generate a regex to extract all possible columns from the data.
    The 'columnName' is the name of the column, and the 'data' is an example of the data.
    Score the result of the extraction using scoreCodeCompletion().
    The optional prompt lets you tune the extraction (could come from the user).
    This is the old interface, which is now deprecated, and replaced by the two-step process of getDataExtractionCandidates() and getDataExtractionFromCandidates()
    """
    getDataExtraction(data: String!, avoidColumnNames: [String!], prompt: String): DataExtractionResponse! @deprecated

    """
    Given some data, generate possible extraction actions on it.
    The 'extractionCandidates' hold the name of the column, and the 'data' is a list of examples of the data.
    Score the result of the extraction using scoreCodeCompletion().
    The optional prompt lets you tune the extraction (could come from the user).
    """
    getDataExtractionFromCandidates(data: [String!]!, extractionCandidates: [DataExtractionCandidateInput!]!, avoidColumnNames: [String!], prompt: String): DataExtractionResponse!

    """
    Given some data, generate possible extraction actions on it.
    The 'columnName' is the name of the column, and the 'data' is a list of examples of the data.
    Score the result of the extraction using scoreCodeCompletion().
    The optional prompt lets you tune the extraction (could come from the user).
    """
    getDataExtractionCandidates(data: [String!]!, avoidColumnNames: [String!], prompt: String): DataExtractionResponse!

    """
    This is the o11y-as-command-line interface, to continue a session started with setInferHelpContext().
    You can also use this to start an un-bound session (that won't have context.)
    """
    inferHelp(previousId:String, author:String, text:String!, mode:InferMode, options:InferOptionsInput): InferResponse!
    """
    Summarize a conversation. previousId is the ID of the previous session, if any. text is whatever extra instructions
    the user attached. statements is the chat history. You can also provide options to control the summary.
    kind is the kind of summary you want. slackChannelInput contains the connection ID and channel ID that this summary is associated with.
    """
    inferSummary(previousId: String, text: String, statements:[ChatStatementInput!]!, kind:SummaryKind, options:InferOptionsInput, slackChannelInput: IncidentSlackchannelInput): InferResponse!
}

enum SummaryKind @goModel(model:"observe/meta/metascalar.SummaryKind") {
    Summary
    Timeline
    Incident
    Retrospective
}

extend type Mutation {
    """
    Score a help response as more or less helpful.
    Any negative value counts as "bad" and any positive value counts as "good."
    """
    scoreHelp(id:String!, score:Int64!): ResultStatus!
    """
    Score a code completion. Positive is "good" and negative is "bad."
    """
    scoreCodeCompletion(id:String!, score:Int64!): ResultStatus!
    """
    Score a particular response in the inference API.
    """
    scoreInference(id: String!, score: Int64!): ResultStatus!

    """
    You can allocate/look up o11y sessions based on the customer ID (implicit)
    and some other ID (user ID or channel ID, for example.) If no thread exists
    within the given lookback, return a new session. Default lookback is 13
    hours. The returned ID can be provided as `previousId` to other functions.
    If any of the other functions allocate a session, they will use the UserId
    as key; however, you can start a brand new unique session by passing some
    other value as key.
    """
    getOrMakeO11ySession(userKey: String!, lookback: Duration): O11ySessionInfo!

    """
    When binding a particular context (or a new context) to a particular
    object, call this function to allocate the appropriate context ID.
    Modes let you specify specific modes (Auto is the default.)
    Note that you can use this to re-start an existing conversation with
    a new context, too, to "switch context".
    """
    setInferHelpContext(previousId: String, author: String, object: ORN!, mode: InferMode, params: InferHelpContextParams): InferResponse!
}

type O11ySessionInfo @goModel(model:"observe/meta/metatypes.O11ySessionInfo") {
    sessionId: String!
    latestTime: Time!
}

"""
InferMode determines what path the AI assistant prefers to resolve a user question.
If no mode is specified, the "Auto" mode is used, which uses previous context
and the question text to figure out the mode. If the question starts with "browse,"
the mode will be assumed to be "Browse," if the question starts with "query," the
mode will be assumed to be "Query," if the question starts with "list" or "show,"
the rest of the question is examined to choose "Browse" or "Query," else the mode
is assumed to be "Documentation."
"""
enum InferMode @goModel(model:"observe/meta/metatypes.InferMode") {
    Auto          # figure out what to do from context
    Summarize     # summarize all the data that is in this thread (including provided in the request)
    Documentation # search Observe documentation, return matching help
    Browse        # search dashboards/datasets in the customer instance
    Query         # search actual payload data
    Suggestions   # suggestions for what to do based on past incidents
}

scalar JSONInt64 @goModel(model:"observe/meta/metascalar.JSONInt64")

type HelpResponse @goModel(model:"observe/meta/metatypes.HelpResponse") {
    items: [HelpResponseItem!]!
}

type HelpResponseItem @goModel(model:"observe/meta/metatypes.HelpResponseItem") {
    sender: String!
    message: String!
    url: String
    """
    Any question you get the answer to, is allocated an ID. This ID can be
    provided for context in subsequent questions, and can also be scored
    with scoreHelp().
    """
    id: String!
}

type HelpRecord @goModel(model:"observe/meta/metakind.HelpRecord") {
    token: String!
    when: Time!
    what: String!
    query: String
    answer: String
    score: Int64
    statements: [InferStatement!]
    mode: InferMode
}

enum CodeCompletionModel @goModel(model:"observe/meta/metatypes.CodeCompletionModel") {
    Prod
    Dev
}

type CodeCompletionResponse @goModel(model:"observe/meta/metatypes.CodeCompletionResponse") {
    errorMessage: String
    suggestions: [CodeCompletion!]
}

type CodeCompletion @goModel(model:"observe/meta/metatypes.CodeCompletion") {
    insert: String
    line: Int64
    id: String!
}

type CodeCompletionColumn @goModel(model:"observe/meta/metatypes.CodeCompletionColumn") {
    name: String!
    type: String!
}

type CodeCompletionDataset @goModel(model:"observe/meta/metatypes.CodeCompletionDataset") {
    refName: String!
    datasetName: String!
    schema: [CodeCompletionColumn!]!
}

type DataExtractionResponse @goModel(model:"observe/meta/metatypes.DataExtractionResponse") {
    errorMessage: String
    extractions: [DataExtraction!]
}

"""
A candidate for data extraction.
"""
input DataExtractionCandidateInput @goModel(model:"observe/meta/metatypes.DataExtractionCandidateInput") {
    statement: String! # the candidate name
    explanation: String! # the sample from the first log, or some other explanation of what you want to extract
    id: String
}

type DataExtraction @goModel(model:"observe/meta/metatypes.DataExtraction") {
    statement: String!
    explanation: String!
    id: String!
}

"""Extra parameters that may be passed into setInferHelpContext()"""
input InferHelpContextParams @goModel(model:"observe/meta/metatypes.InferHelpContextParams") {
    startTime: Time
    duration: Duration
    query: MultiStageQueryInput
}

type InferResponse @goModel(model:"observe/meta/metatypes.InferResponse") {
    error: String
    id: String! @goField(name:"Idtok")
    answer: [InferStatement!]! # display these in order if there's more than one
    mode: InferMode!
}

input InferOptionsInput @goModel(model:"observe/meta/metatypes.InferOptions") {
    flags: [String!]
    params: [ValueKeyValueInput!]
}

interface InferStatement @goModel(model:"observe/meta/metatypes.InferStatement") {
    author: String
    text: String! # display this if you don't know better from the specific type
}

type ChatStatement implements InferStatement @goModel(model:"observe/meta/metatypes.ChatStatement") {
    author: String
    text: String!
    timestamp: Time
    url: String # some clickable URL you might like
    embedding: [Float!] # a vector of floats if we computed an embedding for this piece of text.
}

input ChatStatementInput @goModel(model:"observe/meta/metatypes.ChatStatement") {
    author: String
    text: String!
    timestamp: Time
}

type TableStatement implements InferStatement @goModel(model:"observe/meta/metatypes.TableStatement") {
    author: String
    text: String!
    query: MultiStageQuery!
    endTime: Time!
    seconds: JSONInt64!
    startTime: Time!
}

enum O11yChartKind @goModel(model:"observe/meta/metatypes.O11yChartKind") {
    Line
    Pie
}

type GraphStatement implements InferStatement @goModel(model:"observe/meta/metatypes.GraphStatement") {
    author: String
    text: String!
    query: MultiStageQuery!
    endTime: Time!
    seconds: JSONInt64!
    startTime: Time!
    chartKind: O11yChartKind!
}

type ObjectListStatement implements InferStatement @goModel(model:"observe/meta/metatypes.ObjectListStatement") {
    author: String
    text: String!
    objectType: String!
    objectIds: [ORN!]!
    objectNames: [String!]!
    objectUrls: [String!]
}

type ContextStatement implements InferStatement @goModel(model:"observe/meta/metatypes.ContextStatement") {
    author: String
    text: String!
    context: InferContext!
}

type ResetContextStatement implements InferStatement @goModel(model:"observe/meta/metatypes.ResetContextStatement") {
    author: String
    text: String!
}

type InferContext @goModel(model:"observe/meta/metatypes.InferContext") {
    contextType: String! @goField(name:"getObjectType")
    contextObject: ObjectId
    contextObjectName: String
    contextSchema: [CodeCompletionColumn!]
    contextDatasets: [CodeCompletionDataset!]
    contextList: ObjectListStatement
    contextStartTime: Time
    contextDuration: Duration
}
