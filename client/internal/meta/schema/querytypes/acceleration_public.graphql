interface AccelerableObject @goModel(model: "observe/meta/metatypes.AccelerableObject") {
    accelerationInfo: AccelerationInfo!
    accelerationDisabled: Boolean!
}

type AccelerationError implements ErrorInstance @goModel(model: "observe/meta/metatypes.AccelerationError") {
    """
    The dataset that has the acceleration error.
    """
    datasetId: ObjectId!
    datasetName: String!

    """
    Internal transform ID where the acceleration error occurs.
    """
    transformId: String

    """
    When did the error last occur
    """
    time: Time!

    """
    Error text
    """
    errorText: String!
}

"""
Describes the minimum target staleness of any downstream objects from a dataset:

* Dataset
* Monitor
* Dataset outbound share

Downstream objects may either reference this dataset directly or depend on it
indirectly via other intermediate datasets.

It is not applicable to monitors, since they do not have downstream objects.

Currently only considers configured target staleness.
"""
type MinimumDownstreamTargetStaleness @goModel(model: "observe/meta/metatypes.MinimumDownstreamTargetStaleness") {
    """
    Minimum target staleness of all datasets, monitors, and outbound shares
    downstream of this dataset. Currently this only considers the configured
    target staleness of downstream objects.
    """
    minimumDownstreamTargetStalenessSeconds: Float!

    """
    List of downstream datasets that have the configured target staleness given
    in `minimumDownstreamTargetStalenessSeconds`.
    """
    datasetIds: [ObjectId!]

    """
    List of downstream monitors that have the configured target staleness given
    in `minimumDownstreamTargetStalenessSeconds`.
    """
    monitorIds: [ObjectId!]

    """
    List of downstream dataset outbound shares that have the configured target
    staleness given in `minimumDownstreamTargetStalenessSeconds`.
    """
    shareIds: [ObjectId!]
}

enum AccelerationType @goModel(model: "observe/compiler/comptypes.AccelerationType") {
    """
    Dataset can be accelerated by inserting new rows as they come in. This is
    the most efficient form of acceleration.
    """
    InsertOnly

    """
    Dataset can be accelerated by aggregating new rows as they come in. This
    usually happens when we have a time-based aggregation, ex: timechart.
    Also efficient.
    """
    Aggregation

    """
    Dataset can be accelerated, but it's not insert-only or aggregation.
    Such acceleration usually requires reading more data than just
    the new rows, and rewrite existing data. It is usually less efficient
    than the other types.
    """
    Other

    """
    Dataset cannot be accelerated.
    """
    NotSupported
}

enum AccelerationState @goModel(model: "observe/meta/metatypes.AccelerationState") {
    """
    Dataset is newly created/updated and acceleration has just started. It can
    be queried through inlining.
    """
    Initializing

    """
    Normal operation, we are actively accelerating new data as they come in.
    """
    Live

    """
    Like normal operation (Live), but additionally this dataset is updated as fast
    as possible. As long as this dataset is in live mode, the freshness goal is
    reduced to "zero" and reset to the original value again afterwards.
    """
    LiveMode

    """
    Normal operation, this dataset can't be accelerated, it's always inlined,
    like a view in a database.
    """
    View

    """
    Acceleration is unavailable because the dataset or its upstream dataset is
    broken (has compilation error). The dataset cannot be queried.
    """
    Unavailable

    """
    Acceleration is intentionally disabled, and the dataset can still be queried
    (through inlining). This covers the case where the dataset is not accelerable or
    acceleration is explicitly disabled.
    """
    Disabled

    """
    Acceleration is failing at runtime. As a result querying the dataset may
    return outdated results. This is critical error and usually cannot be fixed
    by the user.
    """
    Error
}

type AccelerationInfo @goModel(model: "observe/meta/metatypes.AccelerationInfo") {

    """
    Live staleness of the dataset. 5min means we may not return data received
    in the last 5 minutes. A float value representing a number of seconds.
    Empty if alwaysAccelerated is true.
    """
    stalenessSeconds: Float

    """
    Configured staleness target of the dataset. 2min means the staleness of
    the dataset should not exceed 2mins. May differ from the originally
    configured value of the dataset if Dataset.freshnessDesired is nil, in
    which case we fill in a default, or if there is a layered setting override.

    This can be empty if alwaysAccelerated is true, the dataset is
    initializing, or there is an internal error processing the dataset. This
    should be filled in for datasets that are disabled or have compilation
    errors, though.
    """
    configuredTargetStalenessSeconds: Float

    """
    The actual target staleness target of the dataset. Note that this can be
    higher than the configured staleness target, due to decaying or credit
    manager overrides. Also if this value is different from the field above,
    it means the dataset is freshness decayed.
    Empty if alwaysAccelerated is true.
    """
    targetStalenessSeconds: Float

    """
    The target staleness of this dataset when taking downstream dataset
    staleness targets and credit manager overrides for this dataset into
    account.  Does not take into account decay or governor overrides for
    downstream datasets.
    Empty if alwaysAccelerated is true.

    How to decipher this value:
    * If effectiveTargetStalenessSeconds > configuredTargetStalenessSeconds, then the credit manager is active on this dataset, and effectiveTargetStalenessSeconds == rateLimitOverrideTargetStalenessSeconds
    * If effectiveTargetStalenessSeconds < configuredTargetStalenessSeconds, then a downstream dataset/monitor has a lower configured freshness goal, check minimumDownstreamTargetStaleness to see where this comes from
    * Otherwise, effectiveTargetStalenessSeconds == configuredTargetStalenessSeconds and the freshness goal is operating as configured
    """
    effectiveTargetStalenessSeconds: Float

    """
    The target staleness override for this dataset from the credit manager, if
    a transform credit rate limit is configured and is causing this dataset's
    configured freshness goal to be overridden.
    """
    rateLimitOverrideTargetStalenessSeconds: Float

    """
    The minimum configured target staleness across all datasets downstream of
    this dataset. Can be used to warn if the current or potential target
    staleness values for this dataset will be ignored due to configured
    staleness targets for downstream datasets.
    """
    minimumDownstreamTargetStaleness: MinimumDownstreamTargetStaleness

    """
    Whether the dataset is "always accelerated", i.e., any query should hit
    accelerated data. If this is true then acceleratedRangeStart and
    targetAcceleratedRangeStart are not used.
    """
    alwaysAccelerated: Boolean


    """
    The list of "accelerated" ranges (materialized ranges). Querying data outside
    of this range can result in inlining and be slow.
    """
    acceleratedRanges: [TimeRange!]!


    """
    The target accelerated ranges. If this value is different from the actual
    accelerated range start, it means we are actively backfilling more data, and
    the difference between the two can be treated as a "progress" indication.
    The target is determined by historical queries.
    """
    targetAcceleratedRanges: [TimeRange!]!

    """
    The freshness time of the dataset.
    """
    freshnessTime: Time

    """
    Effective on demand materialization is either the configured override value
    for the dataset or the default value from the transformer config.
    """
    effectiveOnDemandMaterializationLength: Int64!

    """
    Whether data retention is enabled for this dataset. When disabled, then
    effectiveDataRetentionPeriodDays and effectiveDataRetentionTimestamp are not set.
    """
    dataRetentionEnabled: Boolean!

    """
    Effective data retention period in number of days.
    When requested and data retention is disabled, this field is not returned.
    """
    effectiveDataRetentionPeriodDays: Int64

    """
    Effective timestamp of the data retention period used, i.e. data being valid before this timestamp is deleted.
    Note that the deletion is done at a fixed (randomly-chosen) time during each day, so you may see a few artifacts
    in your data until the actual deletion was done.
    When requested and data retention is disabled, this field is not returned.
    """
    effectiveDataRetentionTimestamp: Time

    """
    The minimum timestamp for temporal datasets. For event datasets, this refers to the valid_from column,
    while for interval and resource datasets, this refers to the valid_to column.
    For non-temporal datasets this is not set.
    Due to the update frequency of this field, it is not guaranteed to be up-to-date and it may not yet be populated.
    """
    minimumDataTimestamp: Time

    """
    If the dataset is not hibernated, this field is null.
    If the dataset is hibernated, this field will be set to the time when it was
    hibernated. The dataset will not automatically accelerate new data.
    You can still query the dataset on the accelerated range and issue manual
    acceleration jobs.
    """
    hibernatedAt: Time

    """
    Acceleration errors. Only not null if the state is "Error". Note that right
    now it only includes acceleration error of the particular dataset, but in
    the future shall include upstream dataset's errors.
    """
    errors: [AccelerationError!]!
}
