extend type Query {
    dataset(id: ObjectId!): Dataset
    datasets(ids: [ObjectId!]!): [DatasetEnumerationResult!]!
    pathsBetweenDatasets(from: ObjectId!, to: ObjectId!, limit: Int64): [RelationshipPath!]!
    pathsBetweenDatasets2(from: [ObjectId!]!, to: ObjectId!, limit: Int64, costModel: RelationshipCostAttributes): RelationshipPathResult!


    """
    You can get boards by some combination of "type" and "name"
    """
    getBoards(datasetId: ObjectId!, type: BoardType, name: String): [Board!]!
    getBoard(id: ObjectId!): Board!

    """
    Returns a list of datasets that would be rematerialized if the given dataset
    is saved with the following definition and whether or not a dataset can skip
    rematerialization. See DryRunDatasetSaveResult for more details.
    """
    getDatasetsAffectedByDatasetUpdate(
      workspaceId: ObjectId!,
      dataset: DatasetInput!
      query: MultiStageQueryInput
    ): DatasetsAffectedByDatasetUpdateResult

    datasetAndMonitorBillingInfo(workspaceId: ObjectId!, atTime: Time): DatasetAndMonitorBillingInfo!
}

extend type Mutation {
    """
    Create a dataset if you don't provide an input id.  It will also make sure
    that the provided transform is published with that dataset. This is the
    general "update the things" function to use.  If dependencyHandling is not
    specified, then the default is to apply changes but ignore downstream
    datasets or errors therein.
    """
    saveDataset(
        workspaceId: ObjectId!,
        dataset: DatasetInput!,
        query: MultiStageQueryInput,
        logDerivedMetricQuery: LogDerivedMetricDefinitionInput,
        dependencyHandling: DependencyHandlingInput,
    ): DatasetSaveResult
    deleteDataset(dsid: ObjectId!, dependencyHandling: DependencyHandlingInput): ResultStatus

    """
    Create a dataset with a built-in transform, if you don't provide an input id.
    It will also make sure that the provided transform is published with that dataset.
    This is the general "update the things" function to use.
    If dependencyHandling is not specified, then the default is to apply changes
    but ignore downstream datasets or errors therein.
    """
    saveBuiltinDataset(
        workspaceId: ObjectId!,
        dataset: DatasetInput!,
        dependencyHandling: DependencyHandlingInput,
        transformInput: BuiltinTransformInput,
    ): DatasetSaveResult

    saveSourceDataset(workspaceId: ObjectId!, datasetDefinition: DatasetDefinitionInput!, sourceTable: SourceTableDefinitionInput!, dependencyHandling: DependencyHandlingInput): DatasetSaveResult

    updateBoard(id: ObjectId!, board: BoardInput!): Board!
    createBoard(datasetId: ObjectId!, type: BoardType!, board: BoardInput!): Board!
    deleteBoard(id: ObjectId!): ResultStatus!

}

type DatasetError @goModel(model: "observe/meta/metatypes.DatasetError") {
    customerId: ObjectId!
    datasetId: ObjectId!
    workspaceName: String!
    datasetName: String!
    time: Time!
    location: String!
    text: String!
    """
    Indicates the dataset has a pre-existing error. The existing error may not
    be the same as this error.
    """
    hasExistingError: Boolean!
}

"""
A dataset could fail to compile either because its OPAL was wrong or
because one of its dependencies' OPAL was wrong. CompilationError of
a dataset tells you the compilation error string and also where the
error originated.
"""
type CompilationError @goModel(model: "observe/meta/metatypes.CompilationError") {
    error: String!
    errorInDatasetId: ObjectId!
}

type Transform @goModel(model: "observe/meta/metatypes.Transform") {
    dataset: Dataset @goField(forceResolver:true)

    """
    The transform id is always the same as the dataset id
    """
    id: ObjectId!

    deleted: Boolean!
    current: TransformVersion
    currentVersion: Time!
    version(version: Time!): TransformVersion @goField(forceResolver: true)
    """
    The transform kind indicates whether the transform is supposed to be OPAL-defined
    or built-in.
    """
    kind: TransformKind
}

"""
The built-in transform kind indicates which kind of data transformation to apply
over the input data to create a dataset. Built-in transforms are data transformation
internal to Observe that we can implement data transformation that cannot be expressed
in plain OPAL.
"""
enum BuiltinTransformKind @goModel(model: "observe/meta/metatypes.BuiltinTransformKind") {
    """
    Data transformation to infer canonical trace representation aka service invocation
    graph out of a dataset containing rows with the span interface shape.
    """
    CanonicalTrace
}

"""
The built-in transform input indicates the type of built-in transformation to apply
over the data and its input definition.
"""
input BuiltinTransformInput @goModel(model: "observe/meta/metatypes.BuiltinTransformInput") {
    """
    Built-in transform kind. See #BuiltinTransformKind for the available built-in transforms.
    """
    kind: BuiltinTransformKind!
    """
    Array of Input definition entities for the dataset transform. Cannot be null.
    """
    input: [InputDefinitionInput!]!
    """
    The configuration for the built-in transform. This is stored as opaque JSON in a string.
    This field may evolve as more configuration options become known.
    """
    config: String
}

"""
The built-in transform definition indicates the type of built-in transformation to apply
over the data and its input definition.
"""
type BuiltinTransformDefinition @goModel(model: "observe/meta/metatypes.BuiltinTransformDefinition") {
    """
    Built-in transform kind. See #BuiltinTransformKind for the available built-in transforms.
    """
    kind: BuiltinTransformKind!
    """
    Array of Input definition entities for the dataset transform. Cannot be null.
    """
    input: [InputDefinition!]!
    """
    The configuration for the built-in transform. This is stored as opaque JSON in a string.
    This field may evolve as more configuration options become known.
    """
    config: String
}

"""
The transform kind indicates the type of transformation to apply
over the data, i.e., OPAL-defined or built-in.
"""
enum TransformKind @goModel(model: "observe/meta/metatypes.TransformKind") {
    OPAL
    Builtin
}

type TransformVersion @goModel(model: "observe/meta/metatypes.TransformVersion") {
    transform: Transform
    savedDate: Time!
    savedBy: User @goField(forceResolver:true)
    savedByInfo: UserInfo! @goField(forceResolver:true)
    outputStage: String! @deprecated(reason: "Use query.outputStage instead")
    stages: [StageQuery!]! @deprecated(reason: "Use query.stages instead")
    parameters: [ParameterSpec!]
    parameterValues: [ParameterBinding!]
    layout: JsonObject @deprecated(reason: "Use query.layout instead")
    query: MultiStageQuery
    builtinTransform: BuiltinTransformDefinition
}

type DatasetSaveResult @goModel(model: "observe/meta/metaparser.DatasetSaveResult") {
    """
    This is what you got out when saving
    """
    dataset: Dataset
    """
    Of the stages provided, which ones were used?
    """
    stageDisposition: StageDisposition
    """
    Datasets that are affected by this change
    """
    affectedDatasets: [ObjectId!]
    """
    Information about errors that occur in the affected, and/or downstream datasets
    """
    errorDatasets: [DatasetError!]
    """
    Changing a dataset definition might make currently materialized data obsolete,
    in which case we dematerialize (throw away) this data and recompute new data.
    This is the list of datasets that would get dematerialized.

    Data is dematerialized when the change to the dataset is significant,
    that is, when it alters transform logic. Minor changes like whitespace and
    comments do not cause dematerialization.

    Note that changing a dataset might cause downstream datasets to get
    dematerialized also.
    """
    dematerializedDatasets: [DatasetMaterialization!]
    """
    The Observe compute credit (OCC) cost of rematerializing affected datasets.
    Note that the datasets in this list might differ from those in dematerializedDatasets
    since this list might include some upstream datasets. In general, don't try
    to correlate elements in this list with elements in other lists; treat them
    independently as much as possible.
    """
    rematerializationCosts: [DatasetCostEstimate!]
}

type DatasetsAffectedByDatasetUpdateResult @goModel(model: "observe/meta/metaparser.DatasetsAffectedByDatasetUpdateResult") {
  """
  Changing a dataset definition might make currently materialized data obsolete,
  in which case we dematerialize (throw away) this data and recompute new data.
  This is the list of datasets that would get dematerialized.

  Data is dematerialized when the change to the dataset is significant,
  that is, when it alters transform logic. Minor changes like whitespace and
  comments do not cause dematerialization.

  Note that changing a dataset might cause downstream datasets to get
  dematerialized also.
  """
  dematerializedDatasets: [DatasetMaterialization!]
  """
  The Observe compute credit (OCC) cost of rematerializing affected datasets.
  Note that the datasets in this list might differ from those in dematerializedDatasets
  since this list might include some upstream datasets. In general, don't try
  to correlate elements in this list with elements in other lists; treat them
  independently as much as possible.
  """
  rematerializationCosts: [DatasetCostEstimate!]
  """
  Returns what datasets are dematerialized when edit-forward is used. If a
  dataset is dematerialized normally but not under edit-forward, this means
  historical data for the dataset may be incorrect/missing.
  """
  editForwardDematerializedDatasets: [DatasetMaterialization!]
}

"""Information about a materialized dataset."""
type DatasetMaterialization @goModel(model: "observe/meta/metatypes.DatasetMaterialization") {
    """Metadata about the dataset."""
    dataset: Dataset

    """Size in bytes of the materialized tables."""
    size: Int64!

    """Time windows that are materialized."""
    windows: [TimeRange!]
}

type StageDisposition @goModel(model: "observe/meta/metatypes.StageDisposition") {
    consumedStages: [String!]
    unusedStages: [String!]
    sharedStages: [String!]
    replacedStages: [String!]
}

enum SaveMode @goModel(model: "observe/meta/metatypes.SaveMode") {
    """
    Only update the dataset ID specified in the operation, disregarding dependencies
    """
    UpdateDataset
    """
    Update the dataset ID specified, and its dependencies, but don't change anything if there's any error that's not ignored
    """
    UpdateDatasetAndDependenciesUnlessNewErrors
    """
    Update the dataset ID specified, and its dependencies, as far as can be done without errors, return errors
    """
    UpdateDatasetAndDependenciesIgnoringAllErrors
    """
    Return what would happen if you updated the dataset ID (only) disregarding dependencies. Do not change database.
    """
    PreflightDataset
    """
    Return what would happen if you updated the dataset ID, including effects on dependencies. Do not change database.
    """
    PreflightDatasetAndDependencies
}

"""
Specifies what type of rematerialization will occur when a dataset is updated
"""
enum RematerializationMode @goModel(model: "observe/meta/metatypes.RematerializationMode") {
    """
    Rematerialize dataset and all downstream dependencies
    """
    Rematerialize
    """
    Skips rematerialization if certain conditions are met, will rematerialize otherwise. Use with
    SaveMode.PreflightDataset to verify rematerialization will not occur for a given dataset update
    before updating the dataset.
    """
    SkipRematerialization
}

input DependencyHandlingInput @goModel(model: "observe/meta/metatypes.DependencyHandling") {
    saveMode: SaveMode
    """
    For saveMode UpdateDatasetAndDependenciesUnlessNewErrors, here are errors that don't count as "new"
    """
    ignoreSpecificErrors: [ObjectId!]
    """
    If no mode is specified, Rematerialize will be used by default
    """
    rematerializationMode: RematerializationMode
}

type DatasetInputDataset @goModel(model: "observe/meta/metatypes.DatasetInputDataset") {
    datasetId: ObjectId!,
    inputRole: InputRole!,
}

enum AccelerationDisabledSource @goModel(model:"observe/meta/metatypes.DatasetMaterializationDisabledSource") {
    Empty
    Monitor
    View
}

type Dataset implements WorkspaceObject & FolderObject & AuditedObject & AccelerableObject @goModel(model: "observe/meta/metatypes.Dataset") {
    id: ObjectId!
    externalId: String!
    version: Time!
    workspaceId: ObjectId!
    kind: DatasetKind!
    name: String!
    path: String!
    description: String
    source: String
    lastUpdateSource: String
    deleted: Boolean!
    latencyDesired: Int64
    freshnessDesired: Int64
    typedefId: ObjectId!
    typedef: Typedef! @deprecated(reason: "use fieldList instead")
    fieldList: [FieldDesc!]
    validFromField: String
    validToField: String
    labelField: String
    iconUrl: String
    primaryKey: [String!]
    keys: [[String!]!]
    foreignKeys: [ForeignKey!]
    relatedKeys: [RelatedKey!]
    groupingKey: GroupingKey
    correlationTagMappings: [CorrelationTagMapping!] @goField(forceResolver:false)
    tags: [TagMapping!] @goField(forceResolver: true)
    """
    Entity tags for organizing and categorizing datasets.
    """
    entityTags: [EntityTagMapping!]! @goField(forceResolver:true)
    versions: [Time!] @goField(forceResolver:true)
    lastSaved: Time!
    isSourceDataset: Boolean
    transform: Transform @goField(forceResolver:true)
    inputs: [DatasetInputDataset!] @goField(forceResolver:true)
    sourceTable: SourceTableDefinition @goField(forceResolver:true)
    pathCost: Int64
    interfaces: [ImplementedInterface!]! @goField(forceResolver:true)
    metrics: [Metric!]! @goField(forceResolver:true)
    boards: [Board!]! @goField(forceResolver:true)
    alignment: TimeAlignment
    compilationError: CompilationError
    managedBy: WorkspaceObject @goField(forceResolver:true)
    managedById: ObjectId
    folderId: ObjectId!
    dataTableViewState: JsonObject
    storageIntegrationId: ObjectId

    """
    Optional custom configured override value of the on demand materialization
    range for the dataset.
    """
    onDemandMaterializationLength: Int64

    defaultDashboardId: ObjectId @goField(forceResolver: true)
    defaultInstanceDashboardId: ObjectId @goField(forceResolver: true)

    accelerable: Boolean!
    accelerationType: AccelerationType!
    accelerationInfo: AccelerationInfo! @goField(forceResolver:true)
    accelerationState: AccelerationState! @goField(forceResolver:true)
    accelerationDisabled: Boolean! @goField(name:materializationDisabled)
    accelerationDisabledSource: AccelerationDisabledSource! @goField(name:materializationDisabledSource)

    eligibleAsView: Boolean!

    """
    If the dataset is not hibernated, this field will be set to null.
    If the dataset is hibernated, this field will be set to the time when it was
    hibernated. The dataset will not automatically accelerate new data.
    You can still query the dataset on the accelerated range and issue manual
    acceleration jobs.
    """
    hibernatedAt: Time @goField(forceResolver:true)

    logDerivedMetricTable: LogDerivedMetricDefinition @goField(forceResolver:true)
    """
    Defines the data retention period of the dataset. We will currently only persist this field but
    it wouldn't take effect. TODO: Also apply it to the data retention manager.
    """
    dataRetentionPeriod: Duration

    datasetDefinitionType: DatasetDefinitionType

    createdBy: UserId!
    createdByInfo: UserInfo! @goField(forceResolver: true)
    updatedBy: UserId!
    updatedByInfo: UserInfo! @goField(forceResolver: true)
    createdDate: Time!
    updatedDate: Time!
}

type DatasetEnumerationResult @goModel(model: "observe/meta/metatypes.DatasetEnumerationResult") {
    id: ObjectId!
    """
    One of 'error' and 'dataset' are set
    """
    error: String
    dataset: Dataset
}

type SourceTablePartitionDefinition @goModel(model: "observe/meta/metatypes.SourceTablePartitionDefinition") {
  name: String!
  intervalStart: Int64!
  intervalEnd: Int64!
}

"""
Specifies the mechanism for how changes are tracked for a source table. None is specified for
non-source tables. Update specifies that and update table is used to track changes. CDC specifies that
Snowflake CDC is enabled for the datastream and is used to track changes.
NOTE: CDC is not widely available / is in development.
"""
enum TableChangeTrackingMechanism @goModel(model: "observe/compiler/comptypes.TableChangeTrackingMechanism") {
    """
    Not specified
    """
    None

    """
    Update table
    """
    UpdateTable

    """
    cdc
    """
    CDC
}

type SourceTableDefinition @goModel(model: "observe/meta/metatypes.SourceTableDefinition") {
    schema: String!
    tableName: String! @deprecated(reason:"use partitions instead")
    partitions: [SourceTablePartitionDefinition!]!
    fields: [SourceTableFieldDefinition!]!
    validFromField: String
    batchSeqField: String
    isInsertOnly: Boolean
    sourceUpdateTableName: String
    """
    Specifies the mechanism for how changes are tracked for a source table.
    """
    tableChangeTrackingMechanism: TableChangeTrackingMechanism
}

type SourceTableFieldDefinition @goModel(model: "observe/meta/metatypes.SourceTableFieldDefinition") {
    name: String!
    sqlType: String!
}

input SourceTableDefinitionInput @goModel(model: "observe/meta/metatypes.SourceTableDefinitionInput") {
    schema: String!
    tableName: String!
    fields: [SourceTableFieldDefinitionInput!]!
    validFromField: String
    batchSeqField: String
    isInsertOnly: Boolean
    sourceUpdateTableName: String
    tableChangeTrackingMechanism: TableChangeTrackingMechanism
}

input SourceTableFieldDefinitionInput @goModel(model: "observe/meta/metatypes.SourceTableFieldDefinitionInput") {
    name: String!
    sqlType: String!
}


type RelationshipPath @goModel(model: "observe/meta/metapath.RelationshipPath") {
    fromDatasetId: ObjectId!
    toDatasetId: ObjectId!
    cost: Int64!
    path: [RelationshipPathElement!]!
}

type RelationshipPathElement @goModel(model: "observe/meta/metapath.RelationshipPathElement") {
    """
    It's moderately expensive to ask for the Dataset, so if you
    can get away with only using toDatasetId, that's better.
    """
    dataset:     Dataset @goField(forceResolver:true)
    toDatasetId: ObjectId!
    """
    One of forwardKey or backwardKey will be used
    """
    forwardKey:  ForeignKey
    reverseKey:  RelatedKey
}

type RelationshipPathResult @goModel(model: "observe/meta/metapath.RelationshipPathResult") {
    paths:    [RelationshipPath!]!
    comments: [String!]!
    errors:   [String!]!
}

input RelationshipDatasetCost @goModel(model: "observe/meta/metapath.RelationshipDatasetCost") {
    dataset:   ObjectId!
    extraCost: Int64!
}

input RelationshipCostAttributes @goModel(model: "observe/meta/metapath.RelationshipCostAttributes") {
    costForwardStep: Int64
    costReverseStep: Int64
    costSwitchDirection: Int64
    costForwardKeysSquared: Int64
    costReverseKeysSquared: Int64
    costKeyDisparitySquared: Int64
    extraDatasetCost: [RelationshipDatasetCost!]
}

type DatasetInputRecord @goModel(model: "observe/meta/metatypes.DatasetInputRecord") {
    id: ObjectId
    label: String!
    description: String
    source: String
    overwriteSource: Boolean
    deleted: Boolean
    latencyDesired: Int64
    freshnessDesired: Int64
    iconUrl: String
    layout: JsonObject
    pathCost: Int64
}

input DatasetInput @goModel(model: "observe/meta/metatypes.DatasetInput") {
    """
    if id is not specified, a new dataset is created
    """
    id: ObjectId
    """
    External identifier for the dataset. Must be unique.  If not provided, an id will be
    generated based on the label.
    Depending on configuration, the id returned by the API may change to match externalId.
    Validation: start with a-z, 2-64 chars, only a-z 0-9 - _ /, max one slash, no trailing slash.
    """
    externalId: String
    label: String!
    description: String
    """
    Format - source/comment. Examples - monitor/471142069, web/user created.
    """
    source: String
    """
    Used only when id is specified - that is to say, only when the dataset is updated.
    """
    overwriteSource: Boolean
    deleted: Boolean
    """
    Specifies if dataset acceleration should be disabled. Set to true if
    dataset materialization is not desired. Defaults to false.
    """
    accelerationDisabled: Boolean @goField(name:materializationDisabled)
    """
    Optional reason given for why a dataset is not accelerated. For example,
    when creating a dataset view, user must set accelerationDisabled to true
    and set accelerationDisabledSource to 'View'. Options include: 'Empty',
    'Monitor', and 'View'. Defaults to 'Empty'.
    """
    accelerationDisabledSource: AccelerationDisabledSource @goField(name:materializationDisabledSource)
    latencyDesired: Int64
    freshnessDesired: Int64
    iconUrl: String
    layout: JsonObject
    pathCost: Int64
    dataTableViewState: JsonObject
    storageIntegrationId: ObjectId
    """
    Max on-demand materialization length for the dataset (in nanoseconds). If not set
    will use the default value in transformer config.
    """
    onDemandMaterializationLength: Int64

    """
    Optional id of the object this dataset is managed by: app, datastream, monitor etc.
    """
    managedById: ObjectId

    """
    Optional list of rules to set the list of users and groups that can access the dataset
    """
    sharingRules: [DatasetSharingRuleInput!]

    """
    Entity tags for organizing and categorizing datasets.
    """
    entityTags: [EntityTagMappingInput!]

    """
    Defines the data retention period of the dataset. We will currently only persist this field but
    it wouldn't take effect. TODO: Also apply it to the data retention manager.
    """
    dataRetentionPeriod: Duration

    """
    The type of dataset definition. Used to specify special dataset types like log derived metrics.
    """
    datasetDefinitionType: DatasetDefinitionType
}

input DatasetSharingRuleInput @goModel(model: "observe/meta/metatypes.DatasetSharingRule") {
    subject: RbacSubjectInput!
    role: DatasetRole!
}

enum DatasetRole @goModel(model: "observe/meta/metatypes.DatasetRole") {
    Editor
    Viewer
}

input DatasetTypedefInput @goModel(model: "observe/compiler/comptypes.ObjectTypedef") {
    anykey: Boolean
    fields: [DatasetFieldDefInput!]
    linkDesc: DatasetLinkSchemaInput
}

input DatasetLinkSchemaInput @goModel(model: "observe/compiler/comptypes.LinkSchema") {
    targetDataset: Int64
    targetStageLabel: String
    targetLabelField: String
    label: String!
    srcFields: [String!]!
    dstFields: [String!]!
}

input DatasetFieldTypeInput @goModel(model: "observe/compiler/comptypes.ObjectFieldType") {
    rep: String!
    def: DatasetTypedefInput
    nullable: Boolean
}

input DatasetFieldDefInput @goModel(model: "observe/compiler/comptypes.ObjectFieldDef") {
    name: String!
    type: DatasetFieldTypeInput!
    isEnum: Boolean
    isSearchable: Boolean
    isHidden: Boolean
    isConst: Boolean
    isMetric: Boolean
}

"""
All of the values of DatasetDefinitionMetadataInput are optional, but you
can't, for example, reference a dataset from another dataset until you define
its primary key, and it won't be an event dataset without having a
validFromField.

"""
input DatasetDefinitionMetadataInput @goModel(model: "observe/meta/metatypes.DatasetDefinitionMetadataInput") {
    validFromField: String
    validToField: String
    labelField: String
    primaryKey: [String!]
    keys: [[String!]!]
}

input DatasetDefinitionInput @goModel(model: "observe/meta/metatypes.DatasetDefinitionInput") {
    dataset: DatasetInput!
    schema: [DatasetFieldDefInput!]
    metadata: DatasetDefinitionMetadataInput
}

type DatasetDoctorReport @goModel(model: "observe/meta/metatypes.DatasetDoctorReport") {

    """
    Some particular dataset was the "seed" of this report -- this is the tip
    of the iceberg, and the most-interesting dataset in the reported datasets
    output.
    """
    doctorForDataset: ObjectId!

    """
    All interesting upstream datasets end up in this flat list -- the actual
    graph can be constructed by following the inputDatasets links.
    """
    datasets: [DatasetReport!]!
}

type ReportEventInfo @goModel(model: "observe/meta/metatypes.ReportEventInfo") {
    text: String!
    time: Time!
}

type DatasetReport @goModel(model: "observe/meta/metatypes.DatasetReport") {

    """
    The dataset this report is for
    """
    datasetId: ObjectId!
    datasetLabel: String!
    workspaceId: ObjectId!
    workspaceLabel: String!

    """
    If the doctor has comments, they go here -- this may include anything
    from "this is not accelerable because of stage X" to "the given name is
    not advised" to "the function name X is deprecated, use Y instead."
    """
    doctorComments: [String!]!

    """
    Each stage may have errors and warnings
    """
    stageNotes: [DatasetStageNote!]!

    """
    Datasets bound as data inputs to this dataset
    """
    inputDatasets: [ObjectId!]!

    accelerationInfo: AccelerationInfo @goField(forceResolver:true)
    ongoingErrorReason: ReportEventInfo @goField(forceResolver:true)
    backfillErrorReason: ReportEventInfo @goField(forceResolver:true)
}

type DatasetStageNote @goModel(model: "observe/meta/metatypes.DatasetStageNote") {
    stageId: String!
    errors: [PipelineSymbol!]
    warnings: [PipelineWarning!]
}



enum BoardType @goModel(model: "observe/meta/metatypes.BoardType") {
    Set
    Singleton
}

type Board @goModel(model: "observe/meta/metatypes.Board") {
    id: ObjectId!
    name: String
    datasetId: ObjectId!
    createdBy: UserId!
    createdByInfo: UserInfo! @goField(forceResolver:true)
    createdByName: String!
    updatedBy: UserId!
    updatedByInfo: UserInfo! @goField(forceResolver:true)
    updatedByName: String!
    createdDate: Time!
    updatedDate: Time!
    isDefault: Boolean!
    board: JsonObject!
    type: BoardType!
    source: String
}

input BoardInput @goModel(model: "observe/meta/metatypes.BoardInput") {
    name: String
    isDefault: Boolean
    board: JsonObject
    source: String
}

type DatasetAndMonitorBillingInfo @goModel(model: "observe/meta/metatypes.DatasetAndMonitorBillingInfo") {
    datasets24h: [ObjectBillingInfo!]!
    monitors24h: [ObjectBillingInfo!]!
}

type ObjectBillingInfo @goModel(model: "observe/meta/metatypes.ObjectBillingInfo") {
    id: ObjectId!
    periodFrom: Time!
    periodTo: Time!
    credits: Float!
}

enum DatasetDefinitionType @goModel(model: "observe/meta/metatypes.DatasetDefinitionType") {
    LogDerivedMetric
}

enum LogDerivedMetricAggregationFunction @goModel(model: "observe/meta/metatypes.LogDerivedMetricAggregationFunction") {
    Count
    CountDistinct
    Sum
    Avg
    Min
    Max
}

interface LogDerivedMetricAggregationConfig @goModel(model: "observe/meta/metatypes.LogDerivedMetricAggregationConfig") {
    function: LogDerivedMetricAggregationFunction!
}

type SimpleLogDerivedMetricAggregationConfig implements LogDerivedMetricAggregationConfig @goModel(model: "observe/meta/metatypes.SimpleLogDerivedMetricAggregationConfig") {
    function: LogDerivedMetricAggregationFunction!
}

type LogDerivedMetricDefinition @goModel(model: "observe/meta/metatypes.LogDerivedMetricDefinition") {
    metricName: String!
    metricType: MetricType!
    unit: String!
    shapingQuery: StageQuery!
    aggregation: LogDerivedMetricAggregation!
    metricTags: [LogMetricTag!]!
    interval: Duration!
}

type LogDerivedMetricAggregation @goModel(model: "observe/meta/metatypes.LogDerivedMetricAggregation") {
    config: LogDerivedMetricAggregationConfig!
    fieldPath: MetricTagPath
}

input MetricTagPathInput @goModel(model: "observe/compiler/comptypes.MetricTag") {
    column: String!
    path: String!
}

input LogDerivedMetricAggregationInput @goModel(model: "observe/meta/metatypes.LogDerivedMetricAggregationInput") {
    config: LogDerivedMetricAggregationConfigInput!
    fieldPath: MetricTagPathInput
}

input LogDerivedMetricAggregationConfigInput @goModel(model: "observe/meta/metatypes.SimpleLogDerivedMetricAggregationConfig") {
    function: LogDerivedMetricAggregationFunction!
}

type LogMetricTag @goModel(model: "observe/meta/metatypes.LogMetricTag") {
    name: String!
    fieldPath: MetricTagPath!
}

input LogMetricTagInput @goModel(model: "observe/meta/metatypes.LogMetricTagInput") {
    name: String!
    fieldPath: MetricTagPathInput!
}

input LogDerivedMetricDefinitionInput @goModel(model: "observe/meta/metatypes.LogMetricDefinitionInput") {
    metricName: String!
    metricType: MetricType
    unit: String
    shapingQuery: StageQueryInput!
    aggregation: LogDerivedMetricAggregationInput!
    metricTags: [LogMetricTagInput!]!
    interval: Duration
}
