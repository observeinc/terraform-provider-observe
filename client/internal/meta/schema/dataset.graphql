extend type Query {
    dataset(id: ObjectId!): Dataset
    datasets(ids: [ObjectId!]!): [DatasetEnumerationResult!]!
    pathsBetweenDatasets(from: ObjectId!, to: ObjectId!, limit: Int64): [RelationshipPath!]!
    pathsBetweenDatasets2(from: [ObjectId!]!, to: ObjectId!, limit: Int64, costModel: RelationshipCostAttributes): RelationshipPathResult!

    """
    The control UI is focused on some particular stage. checkQuery() and friends are helpful
    for that, but sometimes you're looking for a more holostic "what the hell is wrong with
    this dataset" view, which you may be able to get in one swell foop from this call. Note
    that the call may take a few seconds if the dataset has many upstream datasets.
    If upLevels is 0, only the dataset is checked. If upLevels is 1, the dataset and its
    immediate ancestors are checked, and so on. If upLevels is not set at all, then all
    ancestors up to the observation dataset will be checked!
    """
    datasetDoctor(dsid: ObjectId!, upLevels: Int): DatasetDoctorReport

    """
    you can get boards by some combination of "type" and "name"
    """
    getBoards(datasetId: ObjectId!, type: BoardType, name: String): [Board!]!
    getBoard(id: ObjectId!): Board!

    datasetAndMonitorBillingInfo(workspaceId: ObjectId!, atTime: Time): DatasetAndMonitorBillingInfo!
}

extend type Mutation {
    """
    saveDataset will create a dataset if you don't provide an input id.
    It will also make sure that the provided transform is published with
    that dataset. This is the general "update the things" function to use.
    If dependencyHandling is not specified, then the default is to apply
    changes but ignore downstream datasets or errors therein.
    """
    saveDataset(
        workspaceId: ObjectId!,
        dataset: DatasetInput!,
        query: MultiStageQueryInput,
        dependencyHandling: DependencyHandlingInput,
    ): DatasetSaveResult
    deleteDataset(dsid: ObjectId!, dependencyHandling: DependencyHandlingInput): ResultStatus

    saveSourceDataset(workspaceId: ObjectId!, datasetDefinition: DatasetDefinitionInput!, sourceTable: SourceTableDefinitionInput!, dependencyHandling: DependencyHandlingInput): DatasetSaveResult

    updateBoard(id: ObjectId!, board: BoardInput!): Board!
    createBoard(datasetId: ObjectId!, type: BoardType!, board: BoardInput!): Board!
    deleteBoard(id: ObjectId!): ResultStatus!

}

enum DatasetKind @goModel(model: "observe/compiler/comptypes.DatasetKind") {
    Table
    Resource
    Event
    Interval
}

type DatasetError @goModel(model: "observe/meta/metatypes.DatasetError") {
    customerId: ObjectId!
    datasetId: ObjectId!
    workspaceName: String!
    datasetName: String!
    time: Time!
    location: String!
    text: String!
    """
    Indicates the dataset has a pre-existing error. The existing error may not
    be the same as this error.
    """
    hasExistingError: Boolean!
}

"""
A dataset could fail to compile either because its OPAL was wrong or
because one of its dependencies' OPAL was wrong. CompilationError of
a dataset tells you the compilation error string and also where the
error originated.
"""
type CompilationError @goModel(model: "observe/meta/metatypes.CompilationError") {
    error: String!
    errorInDatasetId: ObjectId!
}

type Transform @goModel(model: "observe/meta/metatypes.Transform") {
    dataset: Dataset @goField(forceResolver:true)

    """
    the transform id is always the same as the dataset id
    """
    id: ObjectId!

    """
    currently, OPAL or SQL
    """
    queryLanguage: String!
    deleted: Boolean!
    current: TransformVersion
    currentVersion: Time!
    version(version: Time!): TransformVersion
}

input TransformInput @goModel(model: "observe/meta/metatypes.TransformInput") {
    """
    Must be OPAL, or nothing
    """
    queryLanguage: String
    outputStage: String @deprecated(reason:"Use query.outputStage instead")
    stages: [StageQueryInput!] @deprecated(reason:"Use query.stages instead")
    parameters: [ParameterSpecInput!]
    parameterValues: [ParameterBindingInput!]
    layout: JsonObject @deprecated(reason:"Use query.layout instead")
}

input MultiStageQueryInput @goModel(model: "observe/meta/metatypes.MultiStageQueryInput") {
    outputStage: String!
    stages: [StageQueryInput!]!
    parameters: [ParameterSpecInput!]
    parameterValues: [ParameterBindingInput!]
    layout: JsonObject
}

type MultiStageQuery @goModel(model: "observe/meta/metatypes.MultiStageQuery") {
    outputStage: String!
    stages: [StageQuery!]!
    parameters: [ParameterSpec!]!
    parameterValues: [ParameterBinding!]
    layout: JsonObject
}

type TransformVersion @goModel(model: "observe/meta/metatypes.TransformVersion") {
    transform: Transform
    savedDate: Time!
    savedBy: User @goField(forceResolver:true)
    savedByInfo: UserInfo! @goField(forceResolver:true)
    outputStage: String! @deprecated(reason: "Use query.outputStage instead")
    stages: [StageQuery!]! @deprecated(reason: "Use query.stages instead")
    parameters: [ParameterSpec!]
    parameterValues: [ParameterBinding!]
    layout: JsonObject @deprecated(reason: "Use query.layout instead")
    query: MultiStageQuery!
    # we need some kind of "backfill percent complete"
}

type StageQuery @goModel(model: "observe/meta/metatypes.StageQuery") {
    stageID: String @deprecated(reason: "use id instead")
    id: String! @goField(name:StageID)
    input: [InputDefinition!]!
    params: JsonObject
    pipeline: String!
    layout: JsonObject
    parameters: [ParameterSpec!]
    parameterValues: [ParameterBinding!]
}

input StageQueryInput  @goModel(model: "observe/meta/metatypes.StageQueryInput") {
    stageID: String @deprecated(reason: "use id instead")
    stageId: String @deprecated(reason: "use id instead") @goField(name:StageID)
    """
    make id required when we've removed all deprecated use of stageId
    """
    id: String @goField(name:StageID)
    input: [InputDefinitionInput!]!
    pipeline: String!
    layout: JsonObject
    parameters: [ParameterSpecInput!]
    parameterValues: [ParameterBindingInput!]
}

type DatasetSaveResult @goModel(model: "observe/meta/metaparser.DatasetSaveResult") {
    """
    this is what you got out when saving
    """
    dataset: Dataset
    """
    of the stages provided, which ones were used?
    """
    stageDisposition: StageDisposition
    """
    datasets that are affected by this change
    """
    affectedDatasets: [ObjectId!]
    """
    information about errors that occur in the affected, and/or downstream datasets
    """
    errorDatasets: [DatasetError!]
    """
    Changing a dataset definition might make currently materialized data obsolete,
    in which case we dematerialize (throw away) this data and recompute new data.
    This is the list of datasets that would get dematerialized.

    Data is dematerialized when the change to the dataset is significant,
    that is, when it alters transform logic. Minor changes like whitespace and
    comments do not cause dematerialization.

    Note that changing a dataset might cause downstream datasets to get
    dematerialized also.
    """
    dematerializedDatasets: [DatasetMaterialization!]
    """
    The Observe compute credit (OCC) cost of rematerializing affected datasets.
    Note that the datasets in this list might differ from those in dematerializedDatasets
    since this list might include some upstream datasets. In general, don't try
    to correlate elements in this list with elements in other lists; treat them
    independently as much as possible.
    """
    rematerializationCosts: [DatasetCostEstimate!]
}

"""Information about a materialized dataset."""
type DatasetMaterialization @goModel(model: "observe/meta/metatypes.DatasetMaterialization") {
    """Metadata about the dataset."""
    dataset: Dataset

    """Size in bytes of the materialized tables."""
    size: Int64!

    """Time windows that are materialized."""
    windows: [TimeRange!]
}

type StageDisposition @goModel(model: "observe/meta/metatypes.StageDisposition") {
    consumedStages: [String!]
    unusedStages: [String!]
    sharedStages: [String!]
    replacedStages: [String!]
}

enum SaveMode @goModel(model: "observe/meta/metatypes.SaveMode") {
    """
    Only update the dataset ID specified in the operation, disregarding dependencies
    """
    UpdateDataset
    """
    Update the dataset ID specified, and its dependencies, but don't change anything if there's any error that's not ignored
    """
    UpdateDatasetAndDependenciesUnlessNewErrors
    """
    Update the dataset ID specified, and its dependencies, as far as can be done without errors, return errors
    """
    UpdateDatasetAndDependenciesIgnoringAllErrors
    """
    Return what would happen if you updated the dataset ID (only) disregarding dependencies. Do not change database.
    """
    PreflightDataset
    """
    Return what would happen if you updated the dataset ID, including effects on dependencies. Do not change database.
    """
    PreflightDatasetAndDependencies
}

"""
Specifies what type of rematerialization will occur when a dataset is updated
"""
enum RematerializationMode @goModel(model: "observe/meta/metatypes.RematerializationMode") {
    """
    Rematerialize dataset and all downstream dependencies
    """
    Rematerialize
    """
    Skips rematerialization if certain conditions are met, will rematerialize otherwise. Use with
    SaveMode.PreflightDataset to verify rematerialization will not occur for a given dataset update
    before updating the dataset.
    """
    SkipRematerialization
}

input DependencyHandlingInput @goModel(model: "observe/meta/metatypes.DependencyHandling") {
    saveMode: SaveMode
    """
    For saveMode UpdateDatasetAndDependenciesUnlessNewErrors, here are errors that don't count as "new"
    """
    ignoreSpecificErrors: [ObjectId!]
    """
    If no mode is specified, Rematerialize will be used by default
    """
    rematerializationMode: RematerializationMode
}

type ForeignKey @goModel(model: "observe/meta/metatypes.ForeignKey") {
    targetDataset: Int64
    targetStageLabel: String
    label: String @deprecated(reason: "use id instead")
    targetLabelFieldName: String
    srcFields: [String!]! @deprecated(reason: "use src instead")
    # Since link sources are no longer plain column references, to cleanly model them,
    # I'm creating a new type that contains both column name and path (if any). Plan is to
    # deprecate srcFields in future. 
    src: [LinkField!]!
    dstFields: [String!]!
    id: String
}

"""
A RelatedKey is like a ForeignKey, but it may not be a full
primary key to the target dataset.
"""
type RelatedKey @goModel(model: "observe/meta/metatypes.RelatedKey") {
    targetDataset: Int64!
    label: String!
    srcFields: [String!]
    dstFields: [String!]
}

enum GroupingElementType @goModel(model: "observe/compiler/comptypes.GroupingElementType") {
    Column
    Link
}

"""
If type is Column, value is the column name.
If type is Link, value is the link ID.
"""
type GroupingElement @goModel(model: "observe/compiler/comptypes.GroupingElement") {
    type: GroupingElementType!
    value: String!
}

"""
The GroupingKey represents how the output data is grouped. It usually originates
from when the group_by clause is used in an OPAL aggregate verb.
The elements consist of a mix of links and columns.
Note: When elements is an empty list, it literally represents "group_by()" with no
arguments, meaning that all rows are grouped together in a single group. This is
different from the lack of a grouping, which is represented by Dataset.groupingKey
or TaskResultSchema.groupingKey being null.
"""
type GroupingKey @goModel(model: "observe/compiler/comptypes.GroupingKey") {
    elements: [GroupingElement!]!
}

"""
IndexMetadata represents the metadata information of a dataset of the result schema of a query.
Currently only used for token index.
"""
type IndexMetadata @goModel(model: "observe/compiler/comptypes.IndexMetadata") {
    columns: [String!]
}

type DatasetInputDataset @goModel(model: "observe/meta/metatypes.DatasetInputDataset") {
    datasetId: ObjectId!,
    inputRole: InputRole!,
}

type Dataset implements WorkspaceObject & FolderObject & AuditedObject & AccelerableObject @goModel(model: "observe/meta/metatypes.Dataset") {
    id: ObjectId!
    version: Time!
    workspaceId: ObjectId!
    kind: DatasetKind!
    label: String! @deprecated(reason: "use name instead") @goField(forceResolver: true)
    name: String!
    path: String!
    description: String
    source: String
    lastUpdateSource: String
    deleted: Boolean!
    latencyDesired: Int64
    freshnessDesired: Int64
    typedefId: ObjectId!
    typedef: Typedef! @deprecated(reason: "use fieldList instead")
    fieldList: [FieldDesc!]
    validFromField: String
    validToField: String
    labelField: String
    iconUrl: String
    primaryKey: [String!]
    keys: [[String!]!]
    foreignKeys: [ForeignKey!]
    relatedKeys: [RelatedKey!]
    groupingKey: GroupingKey
    correlationTagMappings: [CorrelationTagMapping!] @goField(forceResolver:false)
    latestPublished: Time @deprecated(reason: "use version instead") @goField(name:version)
    versions: [Time!] @goField(forceResolver:true)
    isSourceDataset: Boolean
    transform: Transform @goField(forceResolver:true)
    inputs: [DatasetInputDataset!] @goField(forceResolver:true)
    sourceTable: SourceTableDefinition @goField(forceResolver:true)
    pathCost: Int64
    interfaces: [ImplementedInterface!]! @goField(forceResolver:true)
    metrics: [Metric!]! @goField(forceResolver:true)
    boards: [Board!]! @goField(forceResolver:true)
    alignment: TimeAlignment
    compilationError: CompilationError
    managedBy: WorkspaceObject @goField(forceResolver:true)
    managedById: ObjectId
    folderId: ObjectId!
    indexMetadata: IndexMetadata @deprecated(reason: "use fieldList.indexDefs instead")
    dataTableViewState: JsonObject

    """
    Optional custom configured override value of the on demand materialization
    range for the dataset.
    """
    onDemandMaterializationLength: Int64

    defaultDashboardId: ObjectId
    defaultInstanceDashboardId: ObjectId

    # AccelerableObject (or fields that should eventually move to that interface)
    accelerable: Boolean!
    accelerationInfo: AccelerationInfo! @goField(forceResolver:true)
    accelerationDisabled: Boolean! @goField(name:materializationDisabled)

    """
    If the dataset is not hibernated, this field will be set to null.
    If the dataset is hibernated, this field will be set to the time when it was
    hibernated. The dataset will not automatically accelerate new data.
    You can still query the dataset on the accelerated range and issue manual
    acceleration jobs.
    """
    hibernatedAt: Time @goField(forceResolver:true)

    # AuditedObject
    createdBy: UserId!
    createdByInfo: UserInfo! @goField(forceResolver: true)
    updatedBy: UserId!
    updatedByInfo: UserInfo! @goField(forceResolver: true)
    createdDate: Time!
    updatedDate: Time!
}

enum MetricType @goModel(model: "observe/compiler/comptypes.MetricType") {
    cumulativeCounter
    counter @deprecated(reason: "This field is no longer supported in set_metric verb.")
    ratePerSec @deprecated(reason: "This field is no longer supported in set_metric verb.")
    delta
    gauge
    tdigest
    sample
}

type MetricTag @goModel(model: "observe/compiler/comptypes.MetricTag") {
    column: String!
    path: String!
}

"""
MetricHeuristics contains information deduced via all kinds of "educated guessing", such
as analysis on metric name, or aggregation based metric discovery. They may be inaccurate.
Any heuristics may be unavailable for any metric, due to missing data or other edge cases
where the heuristic estimation method does not apply.
"""
type MetricHeuristics @goModel(model: "observe/compiler/comptypes.MetricHeuristics") {
    validLinkLabels: [String!]
    numOfPoints: Int64
    cardinality: Int64
    interval: Duration
    intervalStddev: Duration
    """
    The last time this metric was reported. This time could be underreported by at most an hour.

    When a metric has a lastReported of T, here is the information you can extract from it:
    1. the metric was actually reported at the timestamp T
    2. the metric was NEVER reported between [T+1h, now-5m), for fresh metric datasets (most are)
    3. the metric was NEVER reported between [T+1h, last_transform_time), for stale metric datasets (either freshness decayed, or has a high freshness goal)
    In other words, for the common cases where T > now-1h, it's not clear whether the metric is reported between [T, now). We haven't yet found an affordable way to uncover this information.
    """
    lastReported: Time
    tags: [MetricTag!]
}

type Metric @goModel(model: "observe/meta/metatypes.Metric") {
    name: String!
    """
    Format: <dataset-alias>.<metric-name>. If an alias is not defined for the dataset, the name is instead used as the alias
    """
    nameWithPath: String!
    """
    the short display name, not the list of metric labels
    """
    label: String! @deprecated(reason: "We should always use name. Using label causes too much confusion.")
    type: MetricType! @goField(name:MetricType)
    unit: String!
    description: String!
    rollup: String!
    aggregate: String!
    interval: Duration
    suggestedBucketSize: Duration
    """
    Whether the metric has been defined explicitly by user.
    Non-user-defined metrics are discovered by scanning metric data.
    """
    userDefined: Boolean!
    heuristics: MetricHeuristics
    state: MetricState!
}

type Typedef @goModel(model: "observe/meta/metatypes.Typedef") {
    id: ObjectId!
    label: String!
    definition: JsonObject @deprecated(reason: "use the strong typed \"def\" field instead")
    def: ObjectTypedef
}

type DatasetEnumerationResult @goModel(model: "observe/meta/metatypes.DatasetEnumerationResult") {
    id: ObjectId!
    """
    one of 'error' and 'dataset' are set
    """
    error: String
    dataset: Dataset
}

type SourceTablePartitionDefinition @goModel(model: "observe/meta/metatypes.SourceTablePartitionDefinition") {
  name: String!
  intervalStart: Int64!
  intervalEnd: Int64!
}

type SourceTableDefinition @goModel(model: "observe/meta/metatypes.SourceTableDefinition") {
    schema: String!
    tableName: String! @deprecated(reason:"use partitions instead")
    partitions: [SourceTablePartitionDefinition!]!
    fields: [SourceTableFieldDefinition!]!
    validFromField: String
    batchSeqField: String
    isInsertOnly: Boolean
    sourceUpdateTableName: String
}

type SourceTableFieldDefinition @goModel(model: "observe/meta/metatypes.SourceTableFieldDefinition") {
    name: String!
    sqlType: String!
}

input SourceTableDefinitionInput @goModel(model: "observe/meta/metatypes.SourceTableDefinitionInput") {
    schema: String!
    tableName: String!
    fields: [SourceTableFieldDefinitionInput!]!
    validFromField: String
    batchSeqField: String
    isInsertOnly: Boolean
    sourceUpdateTableName: String
}

input SourceTableFieldDefinitionInput @goModel(model: "observe/meta/metatypes.SourceTableFieldDefinitionInput") {
    name: String!
    sqlType: String!
}

# Output from pathsBetweenDatasets()

type RelationshipPath @goModel(model: "observe/meta/metapath.RelationshipPath") {
    fromDatasetId: ObjectId!
    toDatasetId: ObjectId!
    cost: Int64!
    path: [RelationshipPathElement!]!
}

type RelationshipPathElement @goModel(model: "observe/meta/metapath.RelationshipPathElement") {
    """
    it's moderately expensive to ask for the Dataset, so if you
    can get away with only using toDatasetId, that's better.
    """
    dataset:     Dataset @goField(forceResolver:true)
    toDatasetId: ObjectId!
    """
    one of forwardKey or backwardKey will be used
    """
    forwardKey:  ForeignKey
    reverseKey:  RelatedKey
}

type RelationshipPathResult @goModel(model: "observe/meta/metapath.RelationshipPathResult") {
    paths:    [RelationshipPath!]!
    comments: [String!]!
    errors:   [String!]!
}

input RelationshipDatasetCost @goModel(model: "observe/meta/metapath.RelationshipDatasetCost") {
    dataset:   ObjectId!
    extraCost: Int64!
}

input RelationshipCostAttributes @goModel(model: "observe/meta/metapath.RelationshipCostAttributes") {
    costForwardStep: Int64
    costReverseStep: Int64
    costSwitchDirection: Int64
    costForwardKeysSquared: Int64
    costReverseKeysSquared: Int64
    costKeyDisparitySquared: Int64
    extraDatasetCost: [RelationshipDatasetCost!]
}

type DatasetInputRecord @goModel(model: "observe/meta/metatypes.DatasetInputRecord") {
    id: ObjectId
    label: String!
    description: String
    source: String
    overwriteSource: Boolean
    deleted: Boolean
    latencyDesired: Int64
    freshnessDesired: Int64
    iconUrl: String
    layout: JsonObject
    pathCost: Int64
}

input DatasetInput @goModel(model: "observe/meta/metatypes.DatasetInput") {
    """
    if id is not specified, a new dataset is created
    """
    id: ObjectId
    label: String!
    description: String
    """
    Format - source/comment. Examples - monitor/471142069, web/user created.
    """
    source: String
    """
    Used only when id is specified - that is to say, only when the dataset is updated.
    """
    overwriteSource: Boolean
    deleted: Boolean
    accelerationDisabled: Boolean @goField(name:materializationDisabled)
    latencyDesired: Int64
    freshnessDesired: Int64
    iconUrl: String
    layout: JsonObject
    pathCost: Int64
    dataTableViewState: JsonObject
    """
    Max on-demand materialization length for the dataset (in nanoseconds). If not set
    will use the default value in transformer config.
    """
    onDemandMaterializationLength: Int64

    """
    Optional id of the object this dataset is managed by: app, datastream, monitor etc.
    """
    managedById: ObjectId
}

# Warning!
# For implementation reasons, these need to match the field names used
# in the JSONB marshaled values in the database. Because we already have
# existing data in the database, changing the names of these fields would
# require significant backwards compatibility engineering and testing, or
# inserting another layer of data structure translation in the middle.
input DatasetTypedefInput @goModel(model: "observe/compiler/comptypes.ObjectTypedef") {
    anykey: Boolean
    fields: [DatasetFieldDefInput!]
    linkDesc: DatasetLinkSchemaInput
}

input DatasetLinkSchemaInput @goModel(model: "observe/compiler/comptypes.LinkSchema") {
    targetDataset: Int64
    targetStageLabel: String
    targetLabelField: String
    label: String!
    srcFields: [String!]!
    dstFields: [String!]!
}

input DatasetFieldTypeInput @goModel(model: "observe/compiler/comptypes.ObjectFieldType") {
    rep: String!
    def: DatasetTypedefInput
    nullable: Boolean
}

input DatasetFieldDefInput @goModel(model: "observe/compiler/comptypes.ObjectFieldDef") {
    name: String!
    type: DatasetFieldTypeInput!
    isEnum: Boolean
    isSearchable: Boolean
    isHidden: Boolean
    isConst: Boolean
    isMetric: Boolean
}

"""
All of the values of DatasetDefinitionMetadataInput are optional, but you
can't, for example, reference a dataset from another dataset until you define
its primary key, and it won't be an event dataset without having a
validFromField.

"""
input DatasetDefinitionMetadataInput @goModel(model: "observe/meta/metatypes.DatasetDefinitionMetadataInput") {
    validFromField: String
    validToField: String
    labelField: String
    primaryKey: [String!]
    keys: [[String!]!]
}

type ImplementedInterface @goModel(model: "observe/meta/metatypes.ImplementedInterface") {
    path: String!
    mapping: [InterfaceFieldMapping!]!
    interface: InterfaceDefinition! @goField(forceResolver:true) @deprecated(reason:"already not used, see OB-32415")
}

type InterfaceFieldMapping @goModel(model: "observe/meta/metatypes.InterfaceFieldMapping") {
    interfaceField: String!
    field: String!
}

"""
TODO(OB-32415): this type is already not used and pending deprecation.
"""
type InterfaceDefinition @goModel(model: "observe/meta/metatypes.InterfaceDefinition") {
    name: String!
    """
    path is the same as name for platform-defined interfaces
    """
    path: String!
    """
    null for platform-defined interfaces
    """
    workspaceId: ObjectId
    interfaceFields: [InterfaceFieldDefinition!]!
    description: String!
    deprecation: String!
    qualifiers: [String!]!
}

"""
TODO(OB-32415): this type is already not used and pending deprecation.
"""
type InterfaceFieldDefinition @goModel(model: "observe/meta/metatypes.InterfaceFieldDefinition") {
    interfaceField: String!
    rep: String!
    optional: Boolean!
}

input DatasetDefinitionInput @goModel(model: "observe/meta/metatypes.DatasetDefinitionInput") {
    dataset: DatasetInput!
    schema: [DatasetFieldDefInput!]
    metadata: DatasetDefinitionMetadataInput
}

type DatasetDoctorReport @goModel(model: "observe/meta/metatypes.DatasetDoctorReport") {

    """
    Some particular dataset was the "seed" of this report -- this is the tip
    of the iceberg, and the most-interesting dataset in the reported datasets
    output.
    """
    doctorForDataset: ObjectId!

    """
    All interesting upstream datasets end up in this flat list -- the actual
    graph can be constructed by following the inputDatasets links.
    """
    datasets: [DatasetReport!]!
}

type ReportEventInfo @goModel(model: "observe/meta/metatypes.ReportEventInfo") {
    text: String!
    time: Time!
}

type DatasetReport @goModel(model: "observe/meta/metatypes.DatasetReport") {

    """
    The dataset this report is for
    """
    datasetId: ObjectId!
    datasetLabel: String!
    workspaceId: ObjectId!
    workspaceLabel: String!

    """
    If the doctor has comments, they go here -- this may include anything
    from "this is not accelerable because of stage X" to "the given name is
    not advised" to "the function name X is deprecated, use Y instead."
    """
    doctorComments: [String!]!

    """
    each stage may have errors and warnings
    """
    stageNotes: [DatasetStageNote!]!

    """
    inputDatasets are datasets bound as data inputs to this dataset
    """
    inputDatasets: [ObjectId!]!

    """
    accelerationInfo is convenient
    """
    accelerationInfo: AccelerationInfo @goField(forceResolver:true)
    ongoingErrorReason: ReportEventInfo @goField(forceResolver:true)
    backfillErrorReason: ReportEventInfo @goField(forceResolver:true)
}

type DatasetStageNote @goModel(model: "observe/meta/metatypes.DatasetStageNote") {
    stageId: String!
    errors: [PipelineSymbol!]
    warnings: [PipelineWarning!]
}



enum BoardType @goModel(model: "observe/meta/metatypes.BoardType") {
    Set
    Singleton
}

type Board @goModel(model: "observe/meta/metatypes.Board") {
    id: ObjectId!
    name: String
    datasetId: ObjectId!
    createdBy: UserId!
    createdByInfo: UserInfo! @goField(forceResolver:true)
    createdByName: String!
    updatedBy: UserId!
    updatedByInfo: UserInfo! @goField(forceResolver:true)
    updatedByName: String!
    createdDate: Time!
    updatedDate: Time!
    isDefault: Boolean!
    board: JsonObject!
    type: BoardType!
    source: String
}

input BoardInput @goModel(model: "observe/meta/metatypes.BoardInput") {
    name: String
    isDefault: Boolean
    board: JsonObject
    source: String
}

type DatasetAndMonitorBillingInfo @goModel(model: "observe/meta/metatypes.DatasetAndMonitorBillingInfo") {
    datasets24h: [ObjectBillingInfo!]!
    monitors24h: [ObjectBillingInfo!]!
}

type ObjectBillingInfo @goModel(model: "observe/meta/metatypes.ObjectBillingInfo") {
    id: ObjectId!
    periodFrom: Time!
    periodTo: Time!
    credits: Float!
}

# A correlationTagMapping is a mapping from a tag to a path in a dataset.
type CorrelationTagMapping @goModel(model: "observe/compiler/comptypes.CorrelationTagMapping") {
    tag: String!
    path: LinkField!
}
